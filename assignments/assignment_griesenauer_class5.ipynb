{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 5 Assignment: K-Fold Cross-Validation**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "For this assignment you will use the **reg-30-spring-2018.csv** dataset.  This is a dataset that I generated specifically for this semester.  You can find the CSV file in the **data** directory of the class GitHub repository here: [reg-30-spring-2018.csv](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/data/reg-30-spring-2018.csv).\n",
    "\n",
    "You will train 5 neural networks, one for each fold of a 5-fold cross validation and return the out of sample predictions.  You will submit these perdictions to the **submit** function.  See [Assignment #1](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb) for details on how to submit an assignment or check that one was submitted.\n",
    "\n",
    "Complete the following tasks:\n",
    "\n",
    "* Normalize all numerics to zscores and all text/categoricals to dummies.  Do not normalize the *target*.\n",
    "* Your target (y) is the filed named *target*.\n",
    "* If you find any missing values (NA's), replace them with the median values for that column.\n",
    "* Use a 5-fold cross validation and return out of sample predictions.  Your RMSE will not be as good as assignment #4, but this is because #4 was overfit.\n",
    "* Your submission should contain the id (column name *id*), your prediction (column name *pred\"), the expected value (from the **reg-30-spring-2018.csv** dataset, named *y*, and the absolute value of the difference between the expected and predicted (column name *diff*).\n",
    "* You might get warnings about the means of your columns differing from mine.  Do not worry about small differences.  \n",
    "* Your submitted dataframe will have these columns: id, y, pred, diff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions\n",
    "\n",
    "You will see these at the top of every module and assignment.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "        \n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment #5 Sample Code\n",
    "\n",
    "The following code provides a starting point for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:76: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 00011: early stopping\n",
      "Fold score (RMSE): 166.5844268798828\n",
      "Fold #2\n",
      "Epoch 00010: early stopping\n",
      "Fold score (RMSE): 29.828569412231445\n",
      "Fold #3\n",
      "Epoch 00006: early stopping\n",
      "Fold score (RMSE): 136.02328491210938\n",
      "Fold #4\n",
      "Epoch 00008: early stopping\n",
      "Fold score (RMSE): 110.4752197265625\n",
      "Fold #5\n",
      "Epoch 00007: early stopping\n",
      "Fold score (RMSE): 66.40000915527344\n",
      "Final, out of sample score (RMSE): 112.95328521728516\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "key = \"r7Th7Lhul2aj0C93lQNZkA9QZFuc6RW1YfPO4QM2\"  # This is an example key and will not work.\n",
    "file = '/Users/rebekahgriesenauer/Documents/AI/deep_neural_networks/assignments/assignment_griesenauer_class5.ipynb'\n",
    "\n",
    "\n",
    "# Begin assignment\n",
    "path = \"../data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"reg-30-spring-2018.csv\")\n",
    "df = pd.read_csv(filename_read)\n",
    "\n",
    "# Encode the feature vector\n",
    "ids = df['id']\n",
    "df.drop('id',1,inplace=True)\n",
    "\n",
    "#Check to see what columns have null values\n",
    "missing_value_columns = df.columns[df.isna().any()].tolist()\n",
    "#replace missing values with median\n",
    "missing_median(df, 'width')\n",
    "\n",
    "#find columns with numeric data\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#remove \"target\" and \"id\" from numeric columns list\n",
    "numeric_columns.remove('target')\n",
    "#encode numeric columns as z-scores\n",
    "for column in numeric_columns:\n",
    "    encode_numeric_zscore(df, column, mean=None, sd=None)\n",
    "\n",
    "#find columns with non-numeric data\n",
    "text_columns = df.select_dtypes(include = object).columns.tolist()\n",
    "#ecode text/category items to dummies\n",
    "for text_col in text_columns:\n",
    "    encode_text_dummy(df, text_col)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "x,y = to_xy(df, 'target')\n",
    "\n",
    "# Cross-Validate\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "oosDF.to_csv('5.csv',index=False)\n",
    "\n",
    "\n",
    "# Cross-Validate\n",
    "# Build the oos prediction list and calculate the error.    \n",
    "# Write the cross-validated prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-8.165592</td>\n",
       "      <td>17.182148</td>\n",
       "      <td>25.347740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-21.348686</td>\n",
       "      <td>13.705452</td>\n",
       "      <td>35.054138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-26.013430</td>\n",
       "      <td>-17.893250</td>\n",
       "      <td>8.120180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-20.795984</td>\n",
       "      <td>-6.285995</td>\n",
       "      <td>14.509989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-21.365068</td>\n",
       "      <td>-6.749698</td>\n",
       "      <td>14.615371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-10.866996</td>\n",
       "      <td>16.180141</td>\n",
       "      <td>27.047138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-17.973490</td>\n",
       "      <td>-15.344212</td>\n",
       "      <td>2.629278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-21.344086</td>\n",
       "      <td>-5.215250</td>\n",
       "      <td>16.128836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-36.634697</td>\n",
       "      <td>-11.679718</td>\n",
       "      <td>24.954979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>13.215101</td>\n",
       "      <td>10.115127</td>\n",
       "      <td>3.099975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-26.114847</td>\n",
       "      <td>15.861776</td>\n",
       "      <td>41.976624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-2.963598</td>\n",
       "      <td>-47.939716</td>\n",
       "      <td>44.976120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>39.961044</td>\n",
       "      <td>63.889080</td>\n",
       "      <td>23.928036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-125.353180</td>\n",
       "      <td>-16.804270</td>\n",
       "      <td>108.548912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-2.048354</td>\n",
       "      <td>29.602982</td>\n",
       "      <td>31.651335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>12.016312</td>\n",
       "      <td>4.397817</td>\n",
       "      <td>7.618495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-23.559896</td>\n",
       "      <td>-36.444767</td>\n",
       "      <td>12.884871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-50.049709</td>\n",
       "      <td>-124.158401</td>\n",
       "      <td>74.108688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>-20.455130</td>\n",
       "      <td>-14.354690</td>\n",
       "      <td>6.100440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>32.706715</td>\n",
       "      <td>38.992817</td>\n",
       "      <td>6.286102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>48.583778</td>\n",
       "      <td>-5.206667</td>\n",
       "      <td>53.790447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-3.992370</td>\n",
       "      <td>15.745916</td>\n",
       "      <td>19.738287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-20.359522</td>\n",
       "      <td>-7.008925</td>\n",
       "      <td>13.350597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-10.925120</td>\n",
       "      <td>2.762048</td>\n",
       "      <td>13.687168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>234.530075</td>\n",
       "      <td>30.098766</td>\n",
       "      <td>204.431305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-9.960091</td>\n",
       "      <td>-0.718570</td>\n",
       "      <td>9.241521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-34.372551</td>\n",
       "      <td>-45.684330</td>\n",
       "      <td>11.311779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>15.607453</td>\n",
       "      <td>23.967918</td>\n",
       "      <td>8.360465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>-32.721043</td>\n",
       "      <td>-54.498737</td>\n",
       "      <td>21.777695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>29.529924</td>\n",
       "      <td>34.949207</td>\n",
       "      <td>5.419283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1204</td>\n",
       "      <td>-51.202515</td>\n",
       "      <td>-65.284691</td>\n",
       "      <td>14.082176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1205</td>\n",
       "      <td>24.545040</td>\n",
       "      <td>21.677000</td>\n",
       "      <td>2.868040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>1206</td>\n",
       "      <td>-14.168628</td>\n",
       "      <td>-30.787872</td>\n",
       "      <td>16.619244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1207</td>\n",
       "      <td>-16.453304</td>\n",
       "      <td>-11.666183</td>\n",
       "      <td>4.787121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>1208</td>\n",
       "      <td>18.798882</td>\n",
       "      <td>12.193209</td>\n",
       "      <td>6.605673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1209</td>\n",
       "      <td>0.111368</td>\n",
       "      <td>20.281595</td>\n",
       "      <td>20.170227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1210</td>\n",
       "      <td>1.715575</td>\n",
       "      <td>-6.982520</td>\n",
       "      <td>8.698094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1211</td>\n",
       "      <td>24.581532</td>\n",
       "      <td>24.700825</td>\n",
       "      <td>0.119293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1212</td>\n",
       "      <td>70.918869</td>\n",
       "      <td>20.480675</td>\n",
       "      <td>50.438194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1213</td>\n",
       "      <td>3.481645</td>\n",
       "      <td>12.357470</td>\n",
       "      <td>8.875824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1214</td>\n",
       "      <td>1.285788</td>\n",
       "      <td>-34.838165</td>\n",
       "      <td>36.123955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>-29.949289</td>\n",
       "      <td>-42.726738</td>\n",
       "      <td>12.777449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>18.435450</td>\n",
       "      <td>-0.089606</td>\n",
       "      <td>18.525055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>-8.941690</td>\n",
       "      <td>-9.396464</td>\n",
       "      <td>0.454774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>45.085232</td>\n",
       "      <td>-14.693827</td>\n",
       "      <td>59.779060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>-0.596684</td>\n",
       "      <td>-38.695709</td>\n",
       "      <td>38.099026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>1220</td>\n",
       "      <td>-55.703304</td>\n",
       "      <td>-63.588482</td>\n",
       "      <td>7.885178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>1221</td>\n",
       "      <td>-13.585516</td>\n",
       "      <td>-5.375806</td>\n",
       "      <td>8.209709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1222</td>\n",
       "      <td>7.920991</td>\n",
       "      <td>-3.186169</td>\n",
       "      <td>11.107161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1223</td>\n",
       "      <td>11.650258</td>\n",
       "      <td>14.920848</td>\n",
       "      <td>3.270590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1224</td>\n",
       "      <td>-5.176262</td>\n",
       "      <td>-16.907967</td>\n",
       "      <td>11.731705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1225</td>\n",
       "      <td>-0.094892</td>\n",
       "      <td>-13.680417</td>\n",
       "      <td>13.585526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1226</td>\n",
       "      <td>7.351319</td>\n",
       "      <td>26.715734</td>\n",
       "      <td>19.364416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1227</td>\n",
       "      <td>13.784697</td>\n",
       "      <td>10.790571</td>\n",
       "      <td>2.994125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1228</td>\n",
       "      <td>7.582651</td>\n",
       "      <td>-19.228922</td>\n",
       "      <td>26.811573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1229</td>\n",
       "      <td>7.175812</td>\n",
       "      <td>-22.610962</td>\n",
       "      <td>29.786774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1230</td>\n",
       "      <td>21.674953</td>\n",
       "      <td>4.820572</td>\n",
       "      <td>16.854382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1231</td>\n",
       "      <td>10.212440</td>\n",
       "      <td>7.271522</td>\n",
       "      <td>2.940918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1232</td>\n",
       "      <td>-94.416908</td>\n",
       "      <td>-62.944187</td>\n",
       "      <td>31.472721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1233</td>\n",
       "      <td>-8.336206</td>\n",
       "      <td>-29.404806</td>\n",
       "      <td>21.068600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           y        pred        diff\n",
       "0        1   -8.165592   17.182148   25.347740\n",
       "1        2  -21.348686   13.705452   35.054138\n",
       "2        3  -26.013430  -17.893250    8.120180\n",
       "3        4  -20.795984   -6.285995   14.509989\n",
       "4        5  -21.365068   -6.749698   14.615371\n",
       "5        6  -10.866996   16.180141   27.047138\n",
       "6        7  -17.973490  -15.344212    2.629278\n",
       "7        8  -21.344086   -5.215250   16.128836\n",
       "8        9  -36.634697  -11.679718   24.954979\n",
       "9       10   13.215101   10.115127    3.099975\n",
       "10      11  -26.114847   15.861776   41.976624\n",
       "11      12   -2.963598  -47.939716   44.976120\n",
       "12      13   39.961044   63.889080   23.928036\n",
       "13      14 -125.353180  -16.804270  108.548912\n",
       "14      15   -2.048354   29.602982   31.651335\n",
       "15      16   12.016312    4.397817    7.618495\n",
       "16      17  -23.559896  -36.444767   12.884871\n",
       "17      18  -50.049709 -124.158401   74.108688\n",
       "18      19  -20.455130  -14.354690    6.100440\n",
       "19      20   32.706715   38.992817    6.286102\n",
       "20      21   48.583778   -5.206667   53.790447\n",
       "21      22   -3.992370   15.745916   19.738287\n",
       "22      23  -20.359522   -7.008925   13.350597\n",
       "23      24  -10.925120    2.762048   13.687168\n",
       "24      25  234.530075   30.098766  204.431305\n",
       "25      26   -9.960091   -0.718570    9.241521\n",
       "26      27  -34.372551  -45.684330   11.311779\n",
       "27      28   15.607453   23.967918    8.360465\n",
       "28      29  -32.721043  -54.498737   21.777695\n",
       "29      30   29.529924   34.949207    5.419283\n",
       "...    ...         ...         ...         ...\n",
       "1203  1204  -51.202515  -65.284691   14.082176\n",
       "1204  1205   24.545040   21.677000    2.868040\n",
       "1205  1206  -14.168628  -30.787872   16.619244\n",
       "1206  1207  -16.453304  -11.666183    4.787121\n",
       "1207  1208   18.798882   12.193209    6.605673\n",
       "1208  1209    0.111368   20.281595   20.170227\n",
       "1209  1210    1.715575   -6.982520    8.698094\n",
       "1210  1211   24.581532   24.700825    0.119293\n",
       "1211  1212   70.918869   20.480675   50.438194\n",
       "1212  1213    3.481645   12.357470    8.875824\n",
       "1213  1214    1.285788  -34.838165   36.123955\n",
       "1214  1215  -29.949289  -42.726738   12.777449\n",
       "1215  1216   18.435450   -0.089606   18.525055\n",
       "1216  1217   -8.941690   -9.396464    0.454774\n",
       "1217  1218   45.085232  -14.693827   59.779060\n",
       "1218  1219   -0.596684  -38.695709   38.099026\n",
       "1219  1220  -55.703304  -63.588482    7.885178\n",
       "1220  1221  -13.585516   -5.375806    8.209709\n",
       "1221  1222    7.920991   -3.186169   11.107161\n",
       "1222  1223   11.650258   14.920848    3.270590\n",
       "1223  1224   -5.176262  -16.907967   11.731705\n",
       "1224  1225   -0.094892  -13.680417   13.585526\n",
       "1225  1226    7.351319   26.715734   19.364416\n",
       "1226  1227   13.784697   10.790571    2.994125\n",
       "1227  1228    7.582651  -19.228922   26.811573\n",
       "1228  1229    7.175812  -22.610962   29.786774\n",
       "1229  1230   21.674953    4.820572   16.854382\n",
       "1230  1231   10.212440    7.271522    2.940918\n",
       "1231  1232  -94.416908  -62.944187   31.472721\n",
       "1232  1233   -8.336206  -29.404806   21.068600\n",
       "\n",
       "[1233 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df = pd.DataFrame()\n",
    "submit_df['id']= ids\n",
    "submit_df['y']=y\n",
    "submit_df['pred']= oos_pred\n",
    "submit_df['diff']= abs(submit_df['pred']-submit_df['y'])\n",
    "# Submit assignment\n",
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Submitted Assignment #5 for rebekah.griesenauer:\n",
      "You have submitted this assignment 3 times. (this is fine)\n",
      "No warnings on your data. You will probably do well, but no guarantee. :-)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submit(source_file=file,data=submit_df,key=key,no=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
